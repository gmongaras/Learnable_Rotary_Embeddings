Just some tests I ran that didn't really go anywhere. May explore more in the future, but it seems like the RoPE embeddings didn't learn toward high or low frequencies. Perhaps this means the frequency doesn't matter?

Based off this repo (that's actually documented): https://github.com/gmongaras/Cottention_Transformer